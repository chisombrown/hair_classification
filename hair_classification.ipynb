{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hair_classification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2HYfhWDE6KZcZstNB3dX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chisombrown/hair_classification/blob/main/hair_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2TtXPwL9DAB",
        "outputId": "6978d9dc-4463-435b-ba32-c1a7f4e59d2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "\n",
        "print(os.listdir())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "['.config', 'gdrive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5Y2nCgWNW39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6233639-c78d-40ef-ffae-3253e70b25b4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from keras.datasets import mnist\n",
        "from sklearn import ensemble\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2grey\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.feature import hog"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mks_8fc9mqkw"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m2z4EQKtw7u"
      },
      "source": [
        "#access main dir\n",
        "patch_dir = '/content/gdrive/MyDrive/Patch1k'\n",
        "# hair_dir = '/content/gdrive/MyDrive/Patch1k/Hair'\n",
        "# nonhair_dir = '/content/gdrive/MyDrive/Patch1k/NonHair'\n",
        "\n",
        "#access path for hair and nonhair\n",
        "hair_non_hair = [join(patch_dir, 'Hair' ),join(patch_dir, 'NonHair')]\n",
        "# hair_non_hair = [join(patch_dir, hair_dir ),join(patch_dir, nonhair_dir)]\n",
        "#initialise list of paths\n",
        "train_images_paths = []\n",
        "test_images_paths = []\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "for i, dir in enumerate(hair_non_hair):\n",
        "  #get paths to test and train path within each hair and nonhair dirs\n",
        "  test_dir = join(dir, 'Testing')\n",
        "  train_dir = join(dir, 'Training')\n",
        "  # test_dir = '/content/gdrive/MyDrive/Patch1k/Hair/Testing'\n",
        "  # train_dir = '/content/gdrive/MyDrive/Patch1k/Hair/Training'\n",
        "  #loop style taken from stackoverflow https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
        "  train_images_paths += [join(train_dir, f) for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
        "  test_images_paths += [join(test_dir, f) for f in listdir(test_dir) if isfile(join(test_dir, f))]\n",
        "  #assign label to paths\n",
        "  train_labels += [i]*len(listdir(train_dir))\n",
        "  test_labels += [i]*len(listdir(test_dir))\n",
        "  # print(train_images_paths[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIs5Bsf3ELH-"
      },
      "source": [
        "def paths_to_images(image_paths):\n",
        "  \"\"\"\n",
        "  This function converts paths to images and returns a stack of images\n",
        "  \"\"\"\n",
        "  #initialise stack of images with each image just being 227x227 zeros\n",
        "  images = np.zeros((len(image_paths),227,227))\n",
        "  #looping through list of paths and converting to list of images\n",
        "  for i, path in enumerate(image_paths):\n",
        "        image = imread(path)\n",
        "        #if image in colour tranform into black and white\n",
        "        if len(image.shape) == 3:\n",
        "            image = rgb2grey(image)\n",
        "        images[i,:,:] = image\n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAkt7ZO3dVv7"
      },
      "source": [
        "#images in own arrays from files\n",
        "# stack of train images\n",
        "train_images = paths_to_images(train_images_paths)\n",
        "#stack of test images\n",
        "test_images = paths_to_images(test_images_paths)\n",
        "\n",
        "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "#save image patches and labels for easier access\n",
        "np.save('/content/gdrive/MyDrive/train_images_patch',train_images)\n",
        "np.save('/content/gdrive/MyDrive/test_images_patch',test_images)\n",
        "np.save('/content/gdrive/MyDrive/train_labels_patch', train_labels)\n",
        "np.save('/content/gdrive/MyDrive/test_labels_patch', test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtADyVGReUE_"
      },
      "source": [
        "#load saved image patches and labels and shuffle so not memorised\n",
        "\n",
        "train_images = np.load('/content/gdrive/MyDrive/train_images_patch.npy')\n",
        "train_labels = np.load('/content/gdrive/MyDrive/train_labels_patch.npy')\n",
        "train_images, train_labels = shuffle(train_images, train_labels)\n",
        "\n",
        "test_images = np.load('/content/gdrive/MyDrive/test_images_patch.npy')\n",
        "test_labels = np.load('/content/gdrive/MyDrive/test_labels_patch.npy')\n",
        "test_images, test_labels = shuffle(test_images, test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGXuK0LYfWKR"
      },
      "source": [
        "#Get tiny feats\n",
        "def get_tiny_feats(images):\n",
        "  \"\"\"\n",
        "  This function downsamples images and stacks them\n",
        "  \"\"\"\n",
        "  #initialise stack of images with each image just being 16x16 zeros\n",
        "  tiny_images = np.zeros((len(images),16,16))\n",
        "  #looping through list of paths and converting to list of images\n",
        "  for i, image in enumerate(images):        \n",
        "        resized_image = resize(image, (16,16), anti_aliasing=True)\n",
        "        tiny_images[i,:,:] = resized_image\n",
        "  return tiny_images\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCtbgueyaxeu",
        "outputId": "8671f056-16f9-48bc-897b-5ca78dc09907"
      },
      "source": [
        "#Classify tiny feats\n",
        "classifier = ensemble.RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "tiny_train_feats = get_tiny_feats(train_images)\n",
        "tiny_test_feats = get_tiny_feats(test_images)\n",
        "\n",
        "\n",
        "tiny_train_feats = np.reshape(tiny_train_feats, (train_images.shape[0],-1))\n",
        "tiny_test_feats = np.reshape(tiny_test_feats, (test_images.shape[0],-1))\n",
        "\n",
        "classifier.fit(tiny_train_feats, train_labels)\n",
        "\n",
        "classifier.score(tiny_test_feats, test_labels)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47619047619047616"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMgh2nWmmsQa"
      },
      "source": [
        "#Get hog feats\n",
        "def get_hog_feats(images):\n",
        "  \"\"\"\n",
        "  This function creates hog descriptors of the patches\n",
        "  \"\"\"\n",
        "  z=2\n",
        "  y=4\n",
        "  descriptors_stack = []\n",
        "  for i, image in enumerate(images):\n",
        "    hog_descriptor = hog(image,pixels_per_cell=(y,y), cells_per_block=(z,z), feature_vector=True )\n",
        "    #this makes it 2d \n",
        "    hog_descriptor.reshape((-1,len(hog_descriptor)))\n",
        "    descriptors_stack.append(hog_descriptor)\n",
        "  return descriptors_stack\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9OexxXLHXYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee42196-b8ad-4ef4-86b8-477156cbf1fb"
      },
      "source": [
        "#Classify hog feats\n",
        "classifier = ensemble.RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "hog_train_feats = get_hog_feats(train_images)\n",
        "hog_test_feats = get_hog_feats(test_images)\n",
        "\n",
        "hog_train_feats = np.reshape(hog_train_feats, (train_images.shape[0],-1))\n",
        "hog_test_feats = np.reshape(hog_test_feats, (test_images.shape[0],-1))\n",
        "\n",
        "classifier.fit(hog_train_feats, train_labels)\n",
        "classifier.score(hog_test_feats, test_labels)\n",
        "\n",
        "\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45714285714285713"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M6px8dj7ud5",
        "outputId": "3fa7042c-273f-4ac3-9377-4d575ac7e874"
      },
      "source": [
        "hair_prediction = classifier.predict(hog_test_feats)\n",
        "print(hair_prediction)\n",
        "print(len(hair_prediction))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 0 1\n",
            " 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 1 0\n",
            " 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1\n",
            " 0 1 0 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1\n",
            " 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
            "420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr90EvYzFmXW"
      },
      "source": [
        "#Get vgg feats\n",
        " code form https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "#code from https://towardsdatascience.com/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0\n",
        "\n",
        "feats_stack = []\n",
        "for i, path in enumerate(train_images_paths):\n",
        "\n",
        "  model = VGG16(weights='imagenet')   # load the model\n",
        "  model = Model(inputs=model.input, outputs=model.get_layer('block4_pool').output)\n",
        "\n",
        "  img_pth = train_images_paths[0]\n",
        "  img = load_img(img_pth, target_size=(224, 224))#load image in shape 224x224\n",
        "  img = img_to_array(img) # convert the image to an array\n",
        "  # expand dimensions so that it represents a single 'sample'\n",
        "  img = expand_dims(img, axis=0)\n",
        "  # prepare the image (e.g. scale pixel values for the vgg)\n",
        "  img = preprocess_input(img)\n",
        "  # get feature map for first hidden layer\n",
        "  feats = model.predict(img)\n",
        "  feats_stack.append(feats)\n",
        "  model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}