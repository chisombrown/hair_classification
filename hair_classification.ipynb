{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hair_classification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7xRrVVPyY6Z2y7aka5gtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chisombrown/hair_classification/blob/main/hair_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Y2nCgWNW39",
        "outputId": "22473c4b-46bd-46fd-de59-c36640cd489c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from keras.datasets import mnist\n",
        "from sklearn import ensemble\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2grey\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.feature import hog"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dhu_ceyg6Y5"
      },
      "source": [
        "def paths_to_images(image_paths):\n",
        "  \"\"\"\n",
        "  This function converts paths to images and returns a stack of images\n",
        "  \"\"\"\n",
        "  #initialise stack of images with each image just being 227x227 zeros\n",
        "  images = np.zeros((len(image_paths),227,227))\n",
        "  #looping through list of paths and converting to list of images\n",
        "  for i, path in enumerate(image_paths):\n",
        "        image = imread(path)\n",
        "        #if image in colour tranform into black and white\n",
        "        if len(image.shape) == 3:\n",
        "            image = rgb2grey(image)\n",
        "        images[i,:,:] = image\n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-m2z4EQKtw7u"
      },
      "source": [
        "#access main dir\n",
        "patch_dir = '/content/gdrive/MyDrive/Patch1k'\n",
        "# hair_dir = '/content/gdrive/MyDrive/Patch1k/Hair'\n",
        "# nonhair_dir = '/content/gdrive/MyDrive/Patch1k/NonHair'\n",
        "\n",
        "#access path for hair and nonhair\n",
        "hair_non_hair = [join(patch_dir, 'Hair' ),join(patch_dir, 'NonHair')]\n",
        "# hair_non_hair = [join(patch_dir, hair_dir ),join(patch_dir, nonhair_dir)]\n",
        "#initialise list of paths\n",
        "train_images_paths = []\n",
        "test_images_paths = []\n",
        "train_labels = []\n",
        "test_labels = []\n",
        "for i, dir in enumerate(hair_non_hair):\n",
        "  #get paths to test and train path within each hair and nonhair dirs\n",
        "  test_dir = join(dir, 'Testing')\n",
        "  train_dir = join(dir, 'Training')\n",
        "  # test_dir = '/content/gdrive/MyDrive/Patch1k/Hair/Testing'\n",
        "  # train_dir = '/content/gdrive/MyDrive/Patch1k/Hair/Training'\n",
        "  #loop style taken from stackoverflow https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
        "  train_images_paths += [join(train_dir, f) for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
        "  test_images_paths += [join(test_dir, f) for f in listdir(test_dir) if isfile(join(test_dir, f))]\n",
        "  #assign label to paths\n",
        "  train_labels += [i]*len(listdir(train_dir))\n",
        "  test_labels += [i]*len(listdir(test_dir))\n",
        "  # print(train_images_paths[0])\n",
        "\n",
        "\n",
        "# stack of train images\n",
        "train_images = paths_to_images(train_images_paths)\n",
        "#stack of test images\n",
        "test_images = paths_to_images(test_images_paths)\n",
        "\n",
        "# (train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAkt7ZO3dVv7"
      },
      "source": [
        "#save image patches and labels for easier access\n",
        "np.save('train_images_patch',train_images)\n",
        "np.save('test_images_patch',test_images)\n",
        "np.save('train_labels_patch', train_labels)\n",
        "np.save('test_labels_patch', test_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G66uSrydlfL"
      },
      "source": [
        "# np.save(join('train_images_patch','MyDrive' ),train_images)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtADyVGReUE_"
      },
      "source": [
        "#load saved image patches and labels and shuffle so not memorised\n",
        "\n",
        "train_images = np.load('train_images_patch.npy')\n",
        "train_labels = np.load('train_labels_patch.npy')\n",
        "train_images, train_labels = shuffle(train_images, train_labels)\n",
        "\n",
        "test_images = np.load('test_images_patch.npy')\n",
        "test_labels = np.load('test_labels_patch.npy')\n",
        "test_images, test_labels = shuffle(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMgh2nWmmsQa"
      },
      "source": [
        "def get_hog_feats(images):\n",
        "  \"\"\"\n",
        "  This function creates hog descriptors of the patches\n",
        "  \"\"\"\n",
        "  z=2\n",
        "  y=4\n",
        "  descriptors_stack = []\n",
        "  for i, image in enumerate(images):\n",
        "    hog_descriptor = hog(image,pixels_per_cell=(y,y), cells_per_block=(z,z), feature_vector=True )\n",
        "    # hog_descriptor.reshape((1,len(hog_descriptor)))\n",
        "    \n",
        "    #this makes it 2d i believe\n",
        "    hog_descriptor.reshape((-1,len(hog_descriptor)))\n",
        "    descriptors_stack.append(hog_descriptor)\n",
        "  # descriptors_stack = np.concatenate(descriptors_stack)\n",
        "  return descriptors_stack\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGXuK0LYfWKR"
      },
      "source": [
        "def get_tiny_feats(images):\n",
        "  \"\"\"\n",
        "  This function downsamples images and stacks them\n",
        "  \"\"\"\n",
        "  #initialise stack of images with each image just being 16x16 zeros\n",
        "  tiny_images = np.zeros((len(images),16,16))\n",
        "  #looping through list of paths and converting to list of images\n",
        "  for i, image in enumerate(images):        \n",
        "        resized_image = resize(image, (16,16), anti_aliasing=True)\n",
        "        tiny_images[i,:,:] = resized_image\n",
        "  return tiny_images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtnqPQt4kkDW"
      },
      "source": [
        "# train_labels = np.reshape(train_labels, (-1,1))\n",
        "# test_labels = np.reshape(test_labels, (-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9OexxXLHXYJ"
      },
      "source": [
        "classifier = ensemble.RandomForestClassifier(n_estimators = 100)\n",
        "\n",
        "# train_feats = get_tiny_feats(train_images)\n",
        "# test_feats = get_tiny_feats(test_images)\n",
        "\n",
        "# train_feats = np.reshape(train_feats, (train_feats.shape[0],256))\n",
        "train_feats = np.zeros((1680, 108900))\n",
        "train_feats = get_hog_feats(train_images)\n",
        "test_feats = get_hog_feats(test_images)\n",
        "\n",
        "classifier.fit(train_feats, train_labels)\n",
        "\n",
        "test_feats = np.reshape(test_feats, (test_feats.shape[0],256))\n",
        "classifier.score(test_feats, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}